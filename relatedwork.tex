\section{Related Work}

\label{sec:relatedwork}

%But we did not find any work that is close to our target. 
%: using the latency information to predict the performance impact of fixing an existing false sharing instance, without actual fixes.
 
%Prior work tends to breakdown the overhead of parallelization or stalls of cycles into different parts of programs or different hardware unit~\cite{Crovella:1994:PPP:602770.602870, Azimi:2005:OPA:1088149.1088163}, but we did not find any work that is close to our target. 
In this section, we review existing tools in detecting false sharing issues, and other techniques to utilize PMU for dynamic analysis.

\cheetah{} is the first work to predict the potential performance improvement after fixing false sharing problems, relying on access latency information provided by the PMU hardware. Existing work utilizes the latency information to point out variables and instructions suffering with high access latency ~\cite{ibs-sc, ibs-pact}. 

\subsection{False Sharing Detection}

Existing tools in false sharing detection can be classified into different types, based on the method of collecting memory accesses or cache related events. 

\paragraph{Simulation-Based Approaches.} Simulation-based approaches simulate the behavior of program executions and may report possible false sharing problems inside programs~\cite{falseshare:simulator}. Simulation-based approaches generally introduce more than $100\times$ performance overhead and can not simulate large applications. 
%They rely on the input of programmers about specific cache hierarchy and hardware configurations. They share the following shortcoming: they can cause more than $100\times$ performance degradation; Detection results can be far from the real truth; It is hard to scale up to real applications with millions lines of code. 

\paragraph{Instrumentation-Based Approaches.} Tools in this category can be further divided into dynamic instrumentation based approaches~\cite{falseshare:binaryinstrumentation1, falseshare:binaryinstrumentation2, qinzhao}, and static-based or compiler-based approaches~\cite{Predator}.
These approaches generally have large performance overhead, running from $5\times$ slower ~\cite{qinzhao, Predator} to $100\times$ slower~\cite{falseshare:binaryinstrumentation1, falseshare:binaryinstrumentation2}. Predator is the state-of-the-art tool in false sharing detection and uncovers the largest number of false sharing instances~\cite{Predator}. However, their performance overhead is still too high to be used in deployed software. 

%Dynamic instrumentation based approaches do not need the availability of source code, but may fail to report the exact lines with problems if debugging related information does not exist in the binary file. Their performance can vary dramatically, from around $5\times$ slower ~\cite{qinzhao} to more than $100\times$ slower~\cite{falseshare:binaryinstrumentation1, falseshare:binaryinstrumentation2}. Compiler-based instrumentation like Predator can have better performance, with around $5\times$ performance overhead, but needs the availability of source code and can not work on legacy programs without the source code~\cite{Predator}. Predator is the state-of-the-art tool in false sharing detection and uncovers the most number of false sharing problems.  However, all existing tools introduce more than $5\times$ performance overhead and can not be used in real deployment. 

% Hardware performance based approaches
\paragraph{OS-Related Approaches.} Sheriff proposes to turn threads into processes, relies on page-based protection and isolation to capture memory writes, and reports write-write false sharing problems with reasonable overhead (around 20\%)~\cite{Sheriff}. Plastic provides a VMM-based prototype system that combines the Performance Counter Monitoring (PMU) and page granularity analysis (based on page protection)~\cite{OSdetection}. Both Sheriff and Plastic can automatically tolerate serious false sharing problems. However, these tools have their own shortcomings: Sheriff can only work on programs using \texttt{pthreads} libraries, and without ad-hoc synchronizations and sharing-the-stack accesses; Plastic requires that programs should run on the virtual machine environment, which is not applicable for most applications.   

\paragraph{PMU-based approaches.} \emph{PMU-based tools} are introduced because of performance reasons. All existing PMU-based approaches actually detect false sharing by monitoring cache related events. Jayasena et al. use the machine learning approach to derive the potential pattern of false sharing by monitoring  cache misses, TLBs events, interactions among cores, and resources stalls~\cite{mldetect}. DARWIN collects cache coherence events at the first round, then identifies possible memory accesses on data structures with frequent cache invalidations for the second round~\cite{Wicaksono11detectingfalse}. Intel's PTU relies on the PEBS mechanism to track cache invalidated related memory accesses, but it cannot differentiate false sharing and true sharing~\cite{detect:ptu}. However, existing PMU-based tools suffer from the following problems: (1) They cannot report all existing false sharing problems because of sampling on very rare cache events (e.g. cache invalidations)~\cite{mldetect, Wicaksono11detectingfalse, DProf} or have a lot of false positives~\cite{detect:ptu}.  (2) They rely on manual annotation~\cite{DProf}, or experts' expertise~\cite{Wicaksono11detectingfalse, detect:ptu}, or multiple executions to locate the problem~\cite{Wicaksono11detectingfalse}; (3) They cannot provide sufficient information for optimization~\cite{mldetect, Wicaksono11detectingfalse, detect:ptu, DProf}.

%For performance reason, more and more tools turn to the hardware support to detect false sharing problems~\cite{mldetect, openmp, detect:ptu, DProf}. Jayasena et al. propose to collect hardware events such as memory accesses, data caches, TLBs, interactions among cores, and resources stalls, and then use the machine learning approach to derive potential memory patterns for false sharing~\cite{mldetect}. However, their approach misses many false sharing problems since the accuracy highly depends on the training process. DARWIN collects cache coherence events at the first round, then identifies possible memory accesses on data structures that are involved in frequent cache invalidations for the second round~\cite{openmp}. DARWIN requires manual effort or expertise to verify whether false sharing occurs or not. Intel's PTU relies on the memory sampling mechanism but can not differentiate false sharing and true sharing since it discards the temporal information of memory accesses and cannot report detailed memory accesses on a cache line~\cite{detect:ptu}. DProf helps programmers to identify cache misses based on AMD's instruction-based sampling hardware~\cite{DProf}. DProf requires manual annotation to locate data types and object fields, and cannot detect false sharing when multiple objects reside on the same cache line. \\

\cheetah{} specifically addresses these existing problems
%: (1) \cheetah{} does not rely on manual annotation, or experts' expertise, or multiple executions to locate the problem; (2) \Cheetah{} does not have false positives; (3) \Cheetah{} 
and provides much richer information for optimization, including word-level accesses and potential performance impact after fixes. Also, \Cheetah{} provides better effectiveness than existing PMU-based approaches since it samples much richer events like memory accesses. 
%It overcomes the limitations of OS-related approaches and can be used for applications running on either VM or non-VM environment. Comparing to approaches of using simulation and instrumentation, it has very low performance overhead and make it practical to be used in the real deployment.   

%\todo{mention it can work on the mysql.It is also the first work that can predict the performance impact of false sharing problems. }

%\subsection{Other PMU-Related Analysis}
%There are many tools to analyze memory related bottlenecks, not necessarily relate to false sharing problems. 
%By monitoring every memory access, prior tools can analyze memory related bottlenecks, such as SLO~\cite{SLO1}, Valgrind~\cite{Nethercote:2007:VFH:1250734.1250746}, and MemSpy~\cite{Martonosi92}, but they may incur hundreds of times slowdowns. Selectively monitoring memory accesses can still cause 3-5$\times$ overhead, like MACPO~\cite{macpo}. 

%PMU-related techniques are widely used to identify other performance problems because of less than 10\% overhead, such as memory system behavior and data locality. Itzkowitz et al. introduce the memory profiling to Sun ONE Studio, which can collect and analyze memory accesses in sequential programs and report measurement data related to annotated code segment~\cite{DBLP:conf/sc/ItzkowitzWAK03}. Buck and Hollingsworth develope Cache Scope to perform data-centric analysis by using Itanium2 event address registers (EAR)~\cite{DBLP:conf/sc/BuckH04}. HPCToolkit~\cite{ibs-sc} and ArrayTool~\cite{ibs-pact} uses AMD IBS to associate memory access latency with both static and heap allocated data objects, and further provides optimization guidance for array regrouping. However, these general-purpose tools at best can only point out data objects suffering from high access latency, but they do not tell whether the high latency comes from false sharing or not and can not provide rich information to assist optimizations. In contrast, \cheetah{} can correctly identify false sharing problems and associate detailed memory accesses with problematic data objects to help optimizations.
%Cache Scope associates latency with data objects and functions that accessed them. It identifies problematic data objects with poor cache locality and long access latency. With similar techniques, 



% Comments: we will add this in the final version. But there is no need to add this since it haven't been published yet. 
% ScaAnalyzer~\cite{ibs-sc2} studies memory scalability in multithreaded programs. As false sharing is a kind of memory scalability bottleneck, ScaAnalyzer can pinpoint it and assess its impact with the increasing number of cores. 

%\todo{Related work of using PMU latency information}
%\todo{Related work about performance prediction}
%\subsection{Performance Prediction}

%Crovella et. al. provides a method to breakdown the aggregate seconds of parallel overhead into different categories, like serial fraction, synchronization, communication and contention\cite{Crovella:1994:PPP:602770.602870}. Azimi et. al. developed a Statistical Stall Break-down(SSB) model that can quantify the impact of each hardware component, e.g. caches, branch predictor, or other units, on the overall stall~\cite{Azimi:2005:OPA:1088149.1088163}. %\cite{Crovella:1994:PPP:602770.602870} the distinction between productive computation and parallel overhead is useful for both performance diagnosis  and performance prediction. It provides a method to further breakdown the aggregate seconds of parallel overhead into categories like serial fraction, synchronization, communication and contention.  
% Very closed ones:
% http://dl.acm.org/citation.cfm?id=602870 (we should find al related work on this)
% A Framework for Performance Modeling and Prediction
% http://dl.acm.org/citation.cfm?id=1088163
% http://onlinelibrary.wiley.com/doi/10.1002/cpe.1551/full
% http://link.springer.com/chapter/10.1007/978-3-642-14122-5_23
% 
% What is the idea of performance prediction? 
% How to predict? 
%There is no much work in performance prediction. Balsamo et. al.~\cite{Balsamo:2004:MPP:987527.987640} presents an overview on performance prediction on software systems. Fahringer et. al. proposes to predict the performance on distributed memory multiprocessor systems, by relying on compiler analysis. hihi ~\cite{Balsamo:2004:MPP:987527.987640} presents some recent researches that tries to use performance models to quantitatively predict the behavior of software system in the early-phase of development. 

%hihi ~\cite{impactofsharing}
%hihi~\cite{Joao:2012:BIS:2150976.2151001} 

%We are going to utilize the prediction technique that we are utilized to predict the more complicated thread model, not just fork-join models. 

% Ackknowledgement: thanks for the contribution of Guangming Zeng for his source code in collecting the source code. 
