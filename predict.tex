\section{Assessing the Performance Impact}

\label{sec:predictimprove}
%\todo{Adding a picture, maybe similar to Sammati paper}
%\todo{memory bound. Predict memory bound. IO we can't bound. original 100, we remove 80. Latency can be predict to the execution time.  } 
Fixing false sharing problems does not necessarily yield significant performance speedups, even for instances with a large number of cache invalidations~\cite{Sheriff, Predator}. Zhao et. al. even observed that fixing may even slowdown a program because of excessive memory consumption or the lose of locality~\cite{qinzhao}. Reporting insignificant false sharing instances are not false positives, but that increases manual burden for programmers.

To resolve this problem, \cheetah{} makes the first attempt to quantitatively assess the potential performance gain of fixing a false sharing instance. Thus, programmers can focus on severe problems only, avoiding unnecessary manual effort.

\cheetah{}'s assessment is based on the following observations:
\begin{itemize}
\item {\bf Observation 1:} the sampling is evenly distributed over the whole execution. Based on this, we can  use the results of sampling to represent the whole execution. The similar idea is widely used by exiting work like Oprofile and Gprof when they identify the hotspots of function calls and code~\cite{oprofile, DBLP:conf/sigplan/GrahamKM82}.

\item {\bf Observation 2:} PMU hardware provides the latency information (e.g. cycles) of each memory operation. We also observed that the latency of accessing falsely shared objects is significantly higher than that of normal accesses. 

\end{itemize}

Based on these two observations, {\bf we propose to use the sampled cycles to represent the runtime time of an execution and further predict the performance impact of a falsely-shared object $O$}. The assessment is performed in three steps listed as follows. 

\begin{itemize}
\item \cheetah{} first evaluates the performance impact on accesses of this object $O$, as discussed in Section~\ref{sec:impactobject}. 

\item Then \cheetah{} assesses the performance impact on the related threads by fixing this false sharing problem, which is discussed in Section~\ref{sec:impactthread}. 
 
\item In the end, \cheetah{} assesses the performance impact on the application in Section~\ref{sec:impactapp}. 
\end{itemize}


\subsection{Impact on Accesses of the Object}
\label{sec:impactobject}

\cheetah{} first predicts the total cycles of all accesses after fixing. To assess the performance impact of fixing a falsely-shared object $O$, \cheetah{} will collect the following information related to this object $O$:  total cycles of accesses -- $Cycles_O$, total number of accesses -- $Accesses_O$, and the average cycles of every memory access after fixing -- $AverCycles_{nofs}$.

It computes to the total cycles of all accesses after fixing ($PredictCycles_{O}$) according to EQ.(\ref{eq:predictedcyclesofo}).   
\begin{equation}
\label{eq:predictedcyclesofo}
 PredictCycles_{O} = (AverageCycles_{nofs} * Accesses_O);
\end{equation} 

However, it is impossible to know $AverCycles_{nofs}$ for $O$ after fixing without actual fixes. Thus, {\it \cheetah{} utilizes the average cycles of each access in the serial phases to approximate this}. There is no false sharing in serial phases, thus $AverCycles_{nofs}$ represents the best scenario of fixing an existing false sharing instance. In reality, the cycles of every access after fixing can be larger than the $AverCycles_{nofs}$, since fixing false sharing may lead to excessive memory consumption or the lose of locality~\cite{qinzhao}. Thus, our prediction actually provides an upper bound of performance improvement. It is expected that $PredictCycles_{O}$ will be less than the actual cycles -- $Cycles_O$, since fixing a false sharing problem can reduce the execution time of an object.  
 
\subsection{Impact on Related Threads}
\label{sec:impactthread}

After that, \cheetah{} assesses the possible execution time of different threads affected by fixing false sharing of this object $O$. 

\Cheetah{} collects the following information of every thread: the execution time -- $RT_{thread}$, the total number of accesses -- $Accesses_{thread}$, and the total cycles of all memory accesses -- $Cycles_{thread}$.

To collect these numbers, \cheetah{} intercepts the creation of threads by passing a custom function as the start routine. In this custom function, \cheetah{} gets the timestamps of before and after running the thread function, so that it can compute the execution time of a thread -- $RT_{thread}$. To gather the number of accesses and cycles of every thread, \cheetah{} makes every thread to respond the signal handler and records the number of accesses and cycles correspondingly. 

After the collection, \cheetah{} predicts the cycles of related thread ($PredictCycles_{thread}$) as the EQ.(\ref{eq:predictedcyclesofthread}), after fixing false sharing of object $O$. 

\begin{equation}
\label{eq:predictedcyclesofthread}
 PredictCycles_{thread} = Cycles_{thread} - Cycles_{O} + PredictCycles_{O} 
\end{equation} 
 
Based on this, \cheetah{} assesses the predicted runtime of a thread --- $PredictRT_{thread}$ --- as the EQ.(\ref{eq:predictedrtofthread}). We assume that {\bf the execution time is proportional to the cycles of accesses}: the less of cycles means the less of the execution time. 
\begin{equation}
\label{eq:predictedrtofthread}
 PredictRT_{thread} = (PredictCycles_{thread}/Cycles_{thread}) * RT_{thread} 
\end{equation} 

\subsection{Impact on the Application}
\label{sec:impactapp}

In the end, \cheetah{} assesses how fixing a false sharing instance will change the performance of the application. 

Actually, increasing the performance of a thread may not increase the final performance if this  thread is not in the critical path.  
To simplify the prediction and verify our idea, \cheetah{} currently focuses on applications with the normal fork-join model, shown as Figure~\ref{fig:forkjoinmodel}. This model is the most important and widely used model in reality. All applications that we have evaluated in this paper utilizes this fork-join model. The performance assessment will be more complicated if nested threads exist inside an application. 


\begin{figure*}[ht!]
\begin{center}
\includegraphics[width=6in]{figure/forkjoin}
\end{center}
\caption{The fork-join model that \Cheetah{} currently focuses on to assess the impact of false sharing instances. }
\label{fig:forkjoinmodel}
\end{figure*}

\cheetah{} tracks creations and joins of threads in order to verify whether an application belongs to the fork-join model or not. \Cheetah{} also collects the execution time of different serial and parallel phases,  using RDTSC (ReaD-Time Stamp Counter) available on X86 machines~\cite{rtdsc}.  As Figure~\ref{fig:forkjoinmodel}, an application enters the first parallel phase after the first thread creation. The application leaves a parallel phase after all children threads are joined successfully. 

Based on the runtime information about every parallel phase and serial phase, \cheetah{} can assess the final performance impact by recomputing the length of each phase and the total time after fixing: the length of each phase is decided by the thread with the longest execution time, while the total time is equal to the sum of different parallel phases and serial phases. 

After \cheetah{} computes the possible execution time of an application after fixing a false sharing problem, \cheetah{} will compute the potential performance improvement based on EQ.(\ref{eq:improvement}), where runtime is denoted by $RT$. We will report the potential performance improvement for every falsely-shared object in the end as Figure~\ref{fig:lr}. Then programmers can focus only on those ones with serious performance impact. We further verify the precision of \cheetah{}'s assessment in Section~\ref{sec:precision}.

\begin{equation}
\label{eq:improvement}
Perf_{improve}= RT_{App} / PredictRT_{App}
\end{equation}

%We will uses an example to show that. For example, there is a false sharing problem that will involved in the $T1$ and $T2$ of Figure~\ref{fig:forkjoinmodel}, but not other threads.  We will assess the possible runtime of $PredictRT_{T1}$ and $PredictRT_{T2}$. Then we checked that whether these predicted runtime will affect the runtime of parallel phase I by checking whether these two runtime are less than the runtime of $T3$ at first. If it won't, then fixing the false sharing problem won't affect the final performance. Otherwise, we have to recompute the length of parallel phase I, while the length of other phases will keep the same. By doing that, we will get a new runtime for the application. Using the EQ.(\ref{eq:improvement}), we can compute the potential performance improvement of this application by fixing the false sharing problems related to the thread $T1$ and $T2$. 









